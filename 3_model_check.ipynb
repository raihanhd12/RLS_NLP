{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb2679b4",
   "metadata": {},
   "source": [
    "# Model Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622d9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd48af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import humanize\n",
    "\n",
    "\n",
    "def inspect_model_details(model_names):\n",
    "    \"\"\"\n",
    "    Inspect multiple models for a comprehensive comparison, including\n",
    "    architecture, tokenizer, and Hub metadata.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ” COMPREHENSIVE MODEL INSPECTION\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Inisialisasi API untuk mengambil data dari Hugging Face Hub\n",
    "    hf_api = HfApi()\n",
    "    results = {}\n",
    "\n",
    "    for model_name in model_names:\n",
    "        print(f\"\\nðŸ“‹ Inspecting: {model_name}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        try:\n",
    "            # 1. Inspeksi Konfigurasi\n",
    "            config = AutoConfig.from_pretrained(model_name)\n",
    "            info = {\n",
    "                \"model_type\": config.model_type,\n",
    "                # Detail Arsitektur\n",
    "                \"hidden_size\": getattr(config, \"hidden_size\", \"N/A\"),\n",
    "                \"num_layers\": getattr(config, \"num_hidden_layers\", \"N/A\"),\n",
    "                \"num_heads\": getattr(config, \"num_attention_heads\", \"N/A\"),\n",
    "                \"num_parameters\": (\n",
    "                    humanize.intword(config.num_parameters())\n",
    "                    if hasattr(config, \"num_parameters\")\n",
    "                    and callable(config.num_parameters)\n",
    "                    else \"N/A\"\n",
    "                ),\n",
    "                # Detail Klasifikasi\n",
    "                \"num_labels\": config.num_labels,\n",
    "                \"labels\": dict(config.id2label) if hasattr(config, \"id2label\") else {},\n",
    "                \"problem_type\": getattr(config, \"problem_type\", \"Not specified\"),\n",
    "            }\n",
    "\n",
    "            print(\"   [Architecture]\")\n",
    "            print(f\"   - Model Type: {info['model_type']}\")\n",
    "            print(f\"   - Parameters: {info['num_parameters']}\")\n",
    "            print(\n",
    "                f\"   - Layers: {info['num_layers']}, Hidden Size: {info['hidden_size']}, Heads: {info['num_heads']}\"\n",
    "            )\n",
    "\n",
    "            print(\"\\n   [Classification Task]\")\n",
    "            print(f\"   - Problem Type: {info['problem_type']}\")\n",
    "            print(f\"   - Number of Labels: {info['num_labels']}\")\n",
    "            if info[\"labels\"]:\n",
    "                print(f\"   - Categories: {list(info['labels'].values())}\")\n",
    "\n",
    "            # 2. Inspeksi Tokenizer\n",
    "            try:\n",
    "                tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "                info[\"tokenizer_class\"] = tokenizer.__class__.__name__\n",
    "                info[\"vocab_size\"] = humanize.intword(tokenizer.vocab_size)\n",
    "\n",
    "                print(\"\\n   [Tokenizer]\")\n",
    "                print(f\"   - Class: {info['tokenizer_class']}\")\n",
    "                print(f\"   - Vocabulary Size: {info['vocab_size']}\")\n",
    "            except Exception as tokenizer_error:\n",
    "                print(f\"\\n   [Tokenizer]\")\n",
    "                print(f\"   - âŒ Error loading tokenizer: {tokenizer_error}\")\n",
    "                info[\"tokenizer_error\"] = str(tokenizer_error)\n",
    "\n",
    "            # 3. Inspeksi Metadata dari Hugging Face Hub (with better error handling)\n",
    "            try:\n",
    "                model_info_hub = hf_api.model_info(model_name)\n",
    "\n",
    "                # Safe access to attributes\n",
    "                downloads = getattr(model_info_hub, \"downloads\", 0)\n",
    "                likes = getattr(model_info_hub, \"likes\", 0)\n",
    "                last_modified = getattr(model_info_hub, \"lastModified\", None)\n",
    "\n",
    "                info[\"downloads\"] = humanize.intword(downloads) if downloads else \"N/A\"\n",
    "                info[\"likes\"] = humanize.intword(likes) if likes else \"N/A\"\n",
    "\n",
    "                # Safe date formatting\n",
    "                if last_modified:\n",
    "                    if hasattr(last_modified, \"strftime\"):\n",
    "                        info[\"last_modified\"] = last_modified.strftime(\"%Y-%m-%d\")\n",
    "                    else:\n",
    "                        info[\"last_modified\"] = str(last_modified).split(\"T\")[0]\n",
    "                else:\n",
    "                    info[\"last_modified\"] = \"N/A\"\n",
    "\n",
    "                print(\"\\n   [Hub Info]\")\n",
    "                print(f\"   - Downloads: {info['downloads']}\")\n",
    "                print(f\"   - Likes: {info['likes']}\")\n",
    "                print(f\"   - Last Modified: {info['last_modified']}\")\n",
    "\n",
    "            except Exception as hub_error:\n",
    "                print(f\"\\n   [Hub Info]\")\n",
    "                print(f\"   - âŒ Error accessing Hub info: {hub_error}\")\n",
    "                info[\"hub_error\"] = str(hub_error)\n",
    "                info[\"downloads\"] = \"N/A\"\n",
    "                info[\"likes\"] = \"N/A\"\n",
    "                info[\"last_modified\"] = \"N/A\"\n",
    "\n",
    "            results[model_name] = info\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error processing {model_name}: {e}\")\n",
    "            results[model_name] = {\"error\": str(e)}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2561936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” COMPREHENSIVE MODEL INSPECTION\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Inspecting: PaceKW/bert-multilabel-indonesian-hate-speech\n",
      "------------------------------------------------------------\n",
      "   [Architecture]\n",
      "   - Model Type: bert\n",
      "   - Parameters: N/A\n",
      "   - Layers: 12, Hidden Size: 768, Heads: 12\n",
      "\n",
      "   [Classification Task]\n",
      "   - Problem Type: multi_label_classification\n",
      "   - Number of Labels: 12\n",
      "   - Categories: ['HS', 'Abusive', 'HS_Individual', 'HS_Group', 'HS_Religion', 'HS_Race', 'HS_Physical', 'HS_Gender', 'HS_Other', 'HS_Weak', 'HS_Moderate', 'HS_Strong']\n",
      "\n",
      "   [Tokenizer]\n",
      "   - Class: BertTokenizerFast\n",
      "   - Vocabulary Size: 31.9 thousand\n",
      "\n",
      "   [Hub Info]\n",
      "   - Downloads: 39\n",
      "   - Likes: N/A\n",
      "   - Last Modified: 2025-05-16\n",
      "\n",
      "ðŸ“‹ Inspecting: PaceKW/indobert-base-p1-multilabel-indonesian-hate-speech-new\n",
      "------------------------------------------------------------\n",
      "   [Architecture]\n",
      "   - Model Type: bert\n",
      "   - Parameters: N/A\n",
      "   - Layers: 12, Hidden Size: 768, Heads: 12\n",
      "\n",
      "   [Classification Task]\n",
      "   - Problem Type: multi_label_classification\n",
      "   - Number of Labels: 12\n",
      "   - Categories: ['HS', 'Abusive', 'HS_Individual', 'HS_Group', 'HS_Religion', 'HS_Race', 'HS_Physical', 'HS_Gender', 'HS_Other', 'HS_Weak', 'HS_Moderate', 'HS_Strong']\n",
      "\n",
      "   [Tokenizer]\n",
      "   - Class: BertTokenizerFast\n",
      "   - Vocabulary Size: 30.5 thousand\n",
      "\n",
      "   [Hub Info]\n",
      "   - Downloads: 97\n",
      "   - Likes: N/A\n",
      "   - Last Modified: 2025-05-22\n",
      "\n",
      "ðŸ“‹ Inspecting: Aardiiiiy/indobertweet-base-Indonesian-sentiment-analysis\n",
      "------------------------------------------------------------\n",
      "   [Architecture]\n",
      "   - Model Type: bert\n",
      "   - Parameters: N/A\n",
      "   - Layers: 12, Hidden Size: 768, Heads: 12\n",
      "\n",
      "   [Classification Task]\n",
      "   - Problem Type: single_label_classification\n",
      "   - Number of Labels: 3\n",
      "   - Categories: ['Negative', 'Neutral', 'Positive']\n",
      "\n",
      "   [Tokenizer]\n",
      "   - Class: BertTokenizerFast\n",
      "   - Vocabulary Size: 31.9 thousand\n",
      "\n",
      "   [Hub Info]\n",
      "   - Downloads: 3.0 thousand\n",
      "   - Likes: 6\n",
      "   - Last Modified: 2025-05-23\n",
      "\n",
      "ðŸ“‹ Inspecting: Aardiiiiy/EmoSense-ID-Indonesian-Emotion-Classifier\n",
      "------------------------------------------------------------\n",
      "   [Architecture]\n",
      "   - Model Type: bert\n",
      "   - Parameters: N/A\n",
      "   - Layers: 12, Hidden Size: 768, Heads: 12\n",
      "\n",
      "   [Classification Task]\n",
      "   - Problem Type: single_label_classification\n",
      "   - Number of Labels: 8\n",
      "   - Categories: ['Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust']\n",
      "\n",
      "   [Tokenizer]\n",
      "   - Class: BertTokenizerFast\n",
      "   - Vocabulary Size: 30.5 thousand\n",
      "\n",
      "   [Hub Info]\n",
      "   - Downloads: 1.9 thousand\n",
      "   - Likes: 2\n",
      "   - Last Modified: 2025-05-09\n"
     ]
    }
   ],
   "source": [
    "models_to_compare = [\n",
    "    \"PaceKW/bert-multilabel-indonesian-hate-speech\",\n",
    "    \"PaceKW/indobert-base-p1-multilabel-indonesian-hate-speech-new\",\n",
    "    \"Aardiiiiy/indobertweet-base-Indonesian-sentiment-analysis\",\n",
    "    \"Aardiiiiy/EmoSense-ID-Indonesian-Emotion-Classifier\",\n",
    "]\n",
    "\n",
    "detailed_results = inspect_model_details(models_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06d3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf1a48",
   "metadata": {},
   "source": [
    "# Sentiment Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa8c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer:\n",
    "    def __init__(\n",
    "        self, model_name=\"Aardiiiiy/indobertweet-base-Indonesian-sentiment-analysis\"\n",
    "    ):\n",
    "        \"\"\"Initialize sentiment analyzer with IndoBERTweet model\"\"\"\n",
    "        print(\"ðŸ”„ Loading IndoBERTweet sentiment model...\")\n",
    "\n",
    "        # Using pipeline (simplest approach)\n",
    "        self.pipe = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=model_name,\n",
    "            device=0 if torch.cuda.is_available() else -1,\n",
    "        )\n",
    "\n",
    "        # Load tokenizer and model separately for more control if needed\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "        # Based on our inspection - we know exactly what labels exist\n",
    "        self.sentiment_labels = [\"NEGATIVE\", \"NEUTRAL\", \"POSITIVE\"]\n",
    "\n",
    "        print(\"âœ… Sentiment model loaded successfully!\")\n",
    "        print(f\"ðŸ”§ Using device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "        print(f\"ðŸ·ï¸ Labels: {', '.join(self.sentiment_labels)}\")\n",
    "\n",
    "    def predict_single(self, text):\n",
    "        \"\"\"Predict sentiment for a single text\"\"\"\n",
    "        if pd.isna(text) or text is None or text == \"\" or text == \"No Comment\":\n",
    "            return {\"label\": \"NEUTRAL\", \"score\": 0.0, \"confidence\": \"low\"}\n",
    "\n",
    "        try:\n",
    "            result = self.pipe(str(text))\n",
    "            prediction = result[0]\n",
    "\n",
    "            # Add confidence level based on score\n",
    "            if prediction[\"score\"] >= 0.8:\n",
    "                confidence = \"high\"\n",
    "            elif prediction[\"score\"] >= 0.6:\n",
    "                confidence = \"medium\"\n",
    "            else:\n",
    "                confidence = \"low\"\n",
    "\n",
    "            return {\n",
    "                \"label\": prediction[\"label\"],\n",
    "                \"score\": prediction[\"score\"],\n",
    "                \"confidence\": confidence,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting sentiment: {e}\")\n",
    "            return {\"label\": \"NEUTRAL\", \"score\": 0.0, \"confidence\": \"error\"}\n",
    "\n",
    "    def predict_batch(self, texts, batch_size=32):\n",
    "        \"\"\"Predict sentiment for multiple texts efficiently\"\"\"\n",
    "        results = []\n",
    "\n",
    "        # Convert to list if pandas Series\n",
    "        if hasattr(texts, \"tolist\"):\n",
    "            texts = texts.tolist()\n",
    "\n",
    "        print(f\"ðŸ”„ Processing {len(texts)} texts for sentiment analysis...\")\n",
    "        print(f\"ðŸ“Š Batch size: {batch_size}\")\n",
    "\n",
    "        # Process in batches with progress bar\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Analyzing sentiment\"):\n",
    "            batch = texts[i : i + batch_size]\n",
    "\n",
    "            # Clean batch texts\n",
    "            clean_batch = []\n",
    "            for text in batch:\n",
    "                if pd.isna(text) or text is None or text == \"\" or text == \"No Comment\":\n",
    "                    clean_batch.append(\"No Comment\")\n",
    "                else:\n",
    "                    clean_batch.append(str(text))\n",
    "\n",
    "            try:\n",
    "                # Predict batch\n",
    "                batch_results = self.pipe(clean_batch)\n",
    "\n",
    "                # Process results\n",
    "                for j, result in enumerate(batch_results):\n",
    "                    if clean_batch[j] == \"No Comment\":\n",
    "                        results.append(\n",
    "                            {\"label\": \"NEUTRAL\", \"score\": 0.0, \"confidence\": \"low\"}\n",
    "                        )\n",
    "                    else:\n",
    "                        # Add confidence level\n",
    "                        if result[\"score\"] >= 0.8:\n",
    "                            confidence = \"high\"\n",
    "                        elif result[\"score\"] >= 0.6:\n",
    "                            confidence = \"medium\"\n",
    "                        else:\n",
    "                            confidence = \"low\"\n",
    "\n",
    "                        results.append(\n",
    "                            {\n",
    "                                \"label\": result[\"label\"],\n",
    "                                \"score\": result[\"score\"],\n",
    "                                \"confidence\": confidence,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in sentiment batch {i//batch_size + 1}: {e}\")\n",
    "                # Add neutral predictions for failed batch\n",
    "                for _ in range(len(batch)):\n",
    "                    results.append(\n",
    "                        {\"label\": \"NEUTRAL\", \"score\": 0.0, \"confidence\": \"error\"}\n",
    "                    )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def analyze_results(self, results):\n",
    "        \"\"\"Analyze and display sentiment analysis results\"\"\"\n",
    "        total = len(results)\n",
    "\n",
    "        print(f\"\\nðŸ“Š SENTIMENT ANALYSIS SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"ðŸ“ Total texts: {total}\")\n",
    "\n",
    "        # Sentiment distribution\n",
    "        sentiment_counts = {\"POSITIVE\": 0, \"NEGATIVE\": 0, \"NEUTRAL\": 0}\n",
    "        for result in results:\n",
    "            label = result[\"label\"]\n",
    "            sentiment_counts[label] = sentiment_counts.get(label, 0) + 1\n",
    "\n",
    "        print(f\"\\nðŸ’­ Sentiment Distribution:\")\n",
    "        for sentiment, count in sentiment_counts.items():\n",
    "            percentage = (count / total) * 100\n",
    "            emoji = (\n",
    "                \"ðŸ˜Š\"\n",
    "                if sentiment == \"POSITIVE\"\n",
    "                else \"ðŸ˜ž\" if sentiment == \"NEGATIVE\" else \"ðŸ˜\"\n",
    "            )\n",
    "            print(f\"   {emoji} {sentiment}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "        # Confidence distribution\n",
    "        conf_counts = {\"high\": 0, \"medium\": 0, \"low\": 0, \"error\": 0}\n",
    "        for result in results:\n",
    "            conf_counts[result[\"confidence\"]] += 1\n",
    "\n",
    "        print(f\"\\nðŸŽ¯ Confidence Distribution:\")\n",
    "        for conf, count in conf_counts.items():\n",
    "            percentage = (count / total) * 100\n",
    "            print(f\"   {conf.capitalize()}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "        return {\n",
    "            \"total\": total,\n",
    "            \"sentiment_distribution\": sentiment_counts,\n",
    "            \"confidence_distribution\": conf_counts,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50ac7100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Testing SentimentAnalyzer...\n",
      "ðŸ”„ Loading IndoBERTweet sentiment model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sentiment model loaded successfully!\n",
      "ðŸ”§ Using device: CPU\n",
      "ðŸ·ï¸ Labels: NEGATIVE, NEUTRAL, POSITIVE\n",
      "\n",
      "ðŸ§ª Testing individual sentiment predictions:\n",
      "------------------------------------------------------------\n",
      "Text: 'Gimana sih @layananinternet, sinyalnya ilang-ilangan mulu dari pagi di daerah Bekasi. Mana lagi butuh buat kerjaan #internetdown'\n",
      "   ðŸ’­ Sentiment: ðŸ˜ Negative (0.970) - high\n",
      "\n",
      "Text: 'Sumpah, vibe-nya cozy abis buat nugas. Kopinya juga aje gile mantep. Fix bakal jadi langganan! âœ¨'\n",
      "   ðŸ’­ Sentiment: ðŸ˜ Positive (0.997) - high\n",
      "\n",
      "Text: 'Overall experience-nya lumayan sih, cuman servicenya agak lama. Nunggunya ampe stengah jam sndiri.'\n",
      "   ðŸ’­ Sentiment: ðŸ˜ Neutral (0.995) - high\n",
      "\n",
      "Text: 'Desain HP-nya keren, kameranya juga oke. TAPI KENAPA BATERAINYA BOROS BANGET?! Baru setengah hari udah abis ðŸ˜­'\n",
      "   ðŸ’­ Sentiment: ðŸ˜ Neutral (0.841) - high\n",
      "\n",
      "Text: 'Ada yg tau info konser terbaru bulan ini gaes?'\n",
      "   ðŸ’­ Sentiment: ðŸ˜ Neutral (0.998) - high\n",
      "\n",
      "âœ… SentimentAnalyzer test completed!\n"
     ]
    }
   ],
   "source": [
    "# Test SentimentAnalyzer only\n",
    "\n",
    "print(\"ðŸš€ Testing SentimentAnalyzer...\")\n",
    "\n",
    "# Initialize\n",
    "try:\n",
    "    sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "    # Test with some examples\n",
    "    test_texts = [\n",
    "        \"Gimana sih @layananinternet, sinyalnya ilang-ilangan mulu dari pagi di daerah Bekasi. Mana lagi butuh buat kerjaan #internetdown\",\n",
    "        \"Sumpah, vibe-nya cozy abis buat nugas. Kopinya juga aje gile mantep. Fix bakal jadi langganan! âœ¨\",\n",
    "        \"Overall experience-nya lumayan sih, cuman servicenya agak lama. Nunggunya ampe stengah jam sndiri.\",\n",
    "        \"Desain HP-nya keren, kameranya juga oke. TAPI KENAPA BATERAINYA BOROS BANGET?! Baru setengah hari udah abis ðŸ˜­\",\n",
    "        \"Ada yg tau info konser terbaru bulan ini gaes?\",\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nðŸ§ª Testing individual sentiment predictions:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for text in test_texts:\n",
    "        result = sentiment_analyzer.predict_single(text)\n",
    "        sentiment_emoji = (\n",
    "            \"ðŸ˜Š\"\n",
    "            if result[\"label\"] == \"POSITIVE\"\n",
    "            else \"ðŸ˜ž\" if result[\"label\"] == \"NEGATIVE\" else \"ðŸ˜\"\n",
    "        )\n",
    "        print(f\"Text: '{text}'\")\n",
    "        print(\n",
    "            f\"   ðŸ’­ Sentiment: {sentiment_emoji} {result['label']} ({result['score']:.3f}) - {result['confidence']}\"\n",
    "        )\n",
    "        print()\n",
    "\n",
    "    print(\"âœ… SentimentAnalyzer test completed!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error in SentimentAnalyzer: {e}\")\n",
    "    import traceback\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414c2ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦ REALISTIC TWITTER/SOCIAL MEDIA SENTIMENT TEST\n",
      "============================================================\n",
      "ðŸ”„ Loading IndoBERTweet sentiment model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sentiment model loaded successfully!\n",
      "ðŸ”§ Using device: CPU\n",
      "ðŸ·ï¸ Labels: NEGATIVE, NEUTRAL, POSITIVE\n",
      "\n",
      "ðŸ§ª Testing original vs preprocessed on social media texts:\n",
      "------------------------------------------------------------\n",
      "\n",
      "1. 'mantepppp bgt sih ini!! rekomended bgt deh ðŸ‘ðŸ‘'\n",
      "   Original: ðŸ˜ Positive (1.00)\n",
      "\n",
      "2. 'gw suka bgt sama pelayanannya.. ramah2 orangnya'\n",
      "   Original: ðŸ˜ Positive (1.00)\n",
      "\n",
      "3. 'worth it bgt!! fix bakal balik lg kesini'\n",
      "   Original: ðŸ˜ Positive (1.00)\n",
      "\n",
      "4. 'OMG enak banget makanannyaa... puas dehh ðŸ˜'\n",
      "   Cleaned: 'omg enak banget makanannyaa... puas dehh ðŸ˜'\n",
      "   Original: ðŸ˜ Positive (1.00)\n",
      "   Cleaned : ðŸ˜ Positive (1.00)\n",
      "\n",
      "5. 'anjrit lama bgt nunggunyaa... udh kesel'\n",
      "   Original: ðŸ˜ Negative (1.00)\n",
      "\n",
      "6. 'jelek bgt dah pelayanannya.. ga worth it'\n",
      "   Original: ðŸ˜ Negative (1.00)\n",
      "\n",
      "7. 'overpriced bgt, rasa b aja... disappointed'\n",
      "   Original: ðŸ˜ Negative (1.00)\n",
      "\n",
      "8. 'wth... udh bayar mahal service nya kyk gini doang??'\n",
      "   Original: ðŸ˜ Negative (0.97)\n",
      "\n",
      "9. 'lumayan sih, tp masih bisa ditingkatin lg'\n",
      "   Original: ðŸ˜ Neutral (1.00)\n",
      "\n",
      "10. 'biasa aja... nothing special tbh'\n",
      "   Original: ðŸ˜ Negative (0.80)\n",
      "\n",
      "11. 'okee lah.. standar gt'\n",
      "   Original: ðŸ˜ Neutral (0.99)\n",
      "\n",
      "12. 'ada plus minusnya.. overall oke2 aja'\n",
      "   Original: ðŸ˜ Neutral (1.00)\n",
      "\n",
      "13. 'meh'\n",
      "   Original: ðŸ˜ Neutral (0.96)\n",
      "\n",
      "14. 'gg'\n",
      "   Original: ðŸ˜ Neutral (0.75)\n",
      "\n",
      "15. 'nice'\n",
      "   Original: ðŸ˜ Positive (0.87)\n",
      "\n",
      "16. 'wkwk lucu'\n",
      "   Original: ðŸ˜ Positive (0.52)\n",
      "\n",
      "17. 'asek'\n",
      "   Original: ðŸ˜ Negative (0.99)\n",
      "\n",
      "ðŸ“Š ANALYSIS SUMMARY:\n",
      "========================================\n",
      "ðŸ˜Š Positive: 0/17 (0%)\n",
      "ðŸ˜ž Negative: 0/17 (0%)\n",
      "ðŸ˜ Neutral:  0/17 (0%)\n",
      "\n",
      "ðŸ’¡ Key observations:\n",
      "   â€¢ How well does the model handle Indonesian slang?\n",
      "   â€¢ Does preprocessing help with typos and abbreviations?\n",
      "   â€¢ Are very short texts classified correctly?\n",
      "\n",
      "âœ… Social media sentiment test completed!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Simple preprocessing for social media text\"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"@\\w+|http\\S+\", \"\", text)  # Remove mentions & URLs\n",
    "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)  # Remove # but keep text\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Clean spaces\n",
    "    return text\n",
    "\n",
    "\n",
    "# REALISTIC TWITTER-LIKE SENTIMENT TEST\n",
    "print(\"ðŸ¦ REALISTIC TWITTER/SOCIAL MEDIA SENTIMENT TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    sentiment_analyzer = SentimentAnalyzer()\n",
    "\n",
    "    # Realistic social media texts with typos, slang, abbreviations\n",
    "    twitter_texts = [\n",
    "        # Positive tweets\n",
    "        \"mantepppp bgt sih ini!! rekomended bgt deh ðŸ‘ðŸ‘\",\n",
    "        \"gw suka bgt sama pelayanannya.. ramah2 orangnya\",\n",
    "        \"worth it bgt!! fix bakal balik lg kesini\",\n",
    "        \"OMG enak banget makanannyaa... puas dehh ðŸ˜\",\n",
    "        # Negative tweets\n",
    "        \"anjrit lama bgt nunggunyaa... udh kesel\",\n",
    "        \"jelek bgt dah pelayanannya.. ga worth it\",\n",
    "        \"overpriced bgt, rasa b aja... disappointed\",\n",
    "        \"wth... udh bayar mahal service nya kyk gini doang??\",\n",
    "        # Neutral/Mixed\n",
    "        \"lumayan sih, tp masih bisa ditingkatin lg\",\n",
    "        \"biasa aja... nothing special tbh\",\n",
    "        \"okee lah.. standar gt\",\n",
    "        \"ada plus minusnya.. overall oke2 aja\",\n",
    "        # Very short/unclear\n",
    "        \"meh\",\n",
    "        \"gg\",\n",
    "        \"nice\",\n",
    "        \"wkwk lucu\",\n",
    "        \"asek\",\n",
    "    ]\n",
    "\n",
    "    print(\"\\nðŸ§ª Testing original vs preprocessed on social media texts:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for i, original in enumerate(twitter_texts, 1):\n",
    "        preprocessed = preprocess_text(original)\n",
    "\n",
    "        # Predict both\n",
    "        orig_result = sentiment_analyzer.predict_single(original)\n",
    "        prep_result = sentiment_analyzer.predict_single(preprocessed)\n",
    "\n",
    "        print(f\"\\n{i}. '{original}'\")\n",
    "        if original != preprocessed:\n",
    "            print(f\"   Cleaned: '{preprocessed}'\")\n",
    "\n",
    "        # Results with emojis\n",
    "        orig_emoji = (\n",
    "            \"ðŸ˜Š\"\n",
    "            if orig_result[\"label\"] == \"POSITIVE\"\n",
    "            else \"ðŸ˜ž\" if orig_result[\"label\"] == \"NEGATIVE\" else \"ðŸ˜\"\n",
    "        )\n",
    "        prep_emoji = (\n",
    "            \"ðŸ˜Š\"\n",
    "            if prep_result[\"label\"] == \"POSITIVE\"\n",
    "            else \"ðŸ˜ž\" if prep_result[\"label\"] == \"NEGATIVE\" else \"ðŸ˜\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"   Original: {orig_emoji} {orig_result['label']} ({orig_result['score']:.2f})\"\n",
    "        )\n",
    "        if original != preprocessed:\n",
    "            print(\n",
    "                f\"   Cleaned : {prep_emoji} {prep_result['label']} ({prep_result['score']:.2f})\"\n",
    "            )\n",
    "\n",
    "            # Check difference\n",
    "            if orig_result[\"label\"] != prep_result[\"label\"]:\n",
    "                print(\"   ðŸ”„ DIFFERENT PREDICTION!\")\n",
    "            elif abs(orig_result[\"score\"] - prep_result[\"score\"]) > 0.1:\n",
    "                print(\"   ðŸ“Š SCORE CHANGED!\")\n",
    "\n",
    "    # Summary analysis\n",
    "    print(f\"\\nðŸ“Š ANALYSIS SUMMARY:\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Count predictions by type\n",
    "    pos_count = sum(\n",
    "        1\n",
    "        for text in twitter_texts\n",
    "        if sentiment_analyzer.predict_single(text)[\"label\"] == \"POSITIVE\"\n",
    "    )\n",
    "    neg_count = sum(\n",
    "        1\n",
    "        for text in twitter_texts\n",
    "        if sentiment_analyzer.predict_single(text)[\"label\"] == \"NEGATIVE\"\n",
    "    )\n",
    "    neu_count = sum(\n",
    "        1\n",
    "        for text in twitter_texts\n",
    "        if sentiment_analyzer.predict_single(text)[\"label\"] == \"NEUTRAL\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"ðŸ˜Š Positive: {pos_count}/{len(twitter_texts)} ({pos_count/len(twitter_texts)*100:.0f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"ðŸ˜ž Negative: {neg_count}/{len(twitter_texts)} ({neg_count/len(twitter_texts)*100:.0f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"ðŸ˜ Neutral:  {neu_count}/{len(twitter_texts)} ({neu_count/len(twitter_texts)*100:.0f}%)\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nðŸ’¡ Key observations:\")\n",
    "    print(\"   â€¢ How well does the model handle Indonesian slang?\")\n",
    "    print(\"   â€¢ Does preprocessing help with typos and abbreviations?\")\n",
    "    print(\"   â€¢ Are very short texts classified correctly?\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "\n",
    "print(\"\\nâœ… Social media sentiment test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad4fcf",
   "metadata": {},
   "source": [
    "# Emotion Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328c2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionAnalyzer:\n",
    "    def __init__(\n",
    "        self, model_name=\"Aardiiiiy/EmoSense-ID-Indonesian-Emotion-Classifier\"\n",
    "    ):\n",
    "        \"\"\"Initialize emotion analyzer with EmoSense model\"\"\"\n",
    "        print(\"ðŸ”„ Loading EmoSense Indonesian emotion model...\")\n",
    "\n",
    "        # Using pipeline (simplest approach)\n",
    "        self.pipe = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=model_name,\n",
    "            device=0 if torch.cuda.is_available() else -1,\n",
    "        )\n",
    "\n",
    "        # Load tokenizer and model separately for more control if needed\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "        # Based on our inspection - we know exactly what labels exist (Plutchik's 8 emotions)\n",
    "        self.emotion_labels = [\n",
    "            \"Anger\",\n",
    "            \"Anticipation\",\n",
    "            \"Disgust\",\n",
    "            \"Fear\",\n",
    "            \"Joy\",\n",
    "            \"Sadness\",\n",
    "            \"Surprise\",\n",
    "            \"Trust\",\n",
    "        ]\n",
    "\n",
    "        # Emotion emojis for better display\n",
    "        self.emotion_emojis = {\n",
    "            \"Anger\": \"ðŸ˜¡\",\n",
    "            \"Anticipation\": \"ðŸ¤”\",\n",
    "            \"Disgust\": \"ðŸ¤¢\",\n",
    "            \"Fear\": \"ðŸ˜¨\",\n",
    "            \"Joy\": \"ðŸ˜Š\",\n",
    "            \"Sadness\": \"ðŸ˜¢\",\n",
    "            \"Surprise\": \"ðŸ˜²\",\n",
    "            \"Trust\": \"ðŸ¤\",\n",
    "        }\n",
    "\n",
    "        print(\"âœ… Emotion model loaded successfully!\")\n",
    "        print(f\"ðŸ”§ Using device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "        print(f\"ðŸŽ­ Emotions: {', '.join(self.emotion_labels)}\")\n",
    "\n",
    "    def predict_single(self, text):\n",
    "        \"\"\"Predict emotion for a single text\"\"\"\n",
    "        if pd.isna(text) or text is None or text == \"\" or text == \"No Comment\":\n",
    "            return {\"label\": \"Trust\", \"score\": 0.0, \"confidence\": \"low\"}\n",
    "\n",
    "        try:\n",
    "            result = self.pipe(str(text))\n",
    "            prediction = result[0]\n",
    "\n",
    "            # Add confidence level based on score\n",
    "            if prediction[\"score\"] >= 0.8:\n",
    "                confidence = \"high\"\n",
    "            elif prediction[\"score\"] >= 0.6:\n",
    "                confidence = \"medium\"\n",
    "            else:\n",
    "                confidence = \"low\"\n",
    "\n",
    "            return {\n",
    "                \"label\": prediction[\"label\"],\n",
    "                \"score\": prediction[\"score\"],\n",
    "                \"confidence\": confidence,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting emotion: {e}\")\n",
    "            return {\"label\": \"Trust\", \"score\": 0.0, \"confidence\": \"error\"}\n",
    "\n",
    "    def predict_batch(self, texts, batch_size=32):\n",
    "        \"\"\"Predict emotion for multiple texts efficiently\"\"\"\n",
    "        results = []\n",
    "\n",
    "        # Convert to list if pandas Series\n",
    "        if hasattr(texts, \"tolist\"):\n",
    "            texts = texts.tolist()\n",
    "\n",
    "        print(f\"ðŸ”„ Processing {len(texts)} texts for emotion analysis...\")\n",
    "        print(f\"ðŸ“Š Batch size: {batch_size}\")\n",
    "\n",
    "        # Process in batches with progress bar\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Analyzing emotions\"):\n",
    "            batch = texts[i : i + batch_size]\n",
    "\n",
    "            # Clean batch texts\n",
    "            clean_batch = []\n",
    "            for text in batch:\n",
    "                if pd.isna(text) or text is None or text == \"\" or text == \"No Comment\":\n",
    "                    clean_batch.append(\"No Comment\")\n",
    "                else:\n",
    "                    clean_batch.append(str(text))\n",
    "\n",
    "            try:\n",
    "                # Predict batch\n",
    "                batch_results = self.pipe(clean_batch)\n",
    "\n",
    "                # Process results\n",
    "                for j, result in enumerate(batch_results):\n",
    "                    if clean_batch[j] == \"No Comment\":\n",
    "                        results.append(\n",
    "                            {\"label\": \"Trust\", \"score\": 0.0, \"confidence\": \"low\"}\n",
    "                        )\n",
    "                    else:\n",
    "                        # Add confidence level\n",
    "                        if result[\"score\"] >= 0.8:\n",
    "                            confidence = \"high\"\n",
    "                        elif result[\"score\"] >= 0.6:\n",
    "                            confidence = \"medium\"\n",
    "                        else:\n",
    "                            confidence = \"low\"\n",
    "\n",
    "                        results.append(\n",
    "                            {\n",
    "                                \"label\": result[\"label\"],\n",
    "                                \"score\": result[\"score\"],\n",
    "                                \"confidence\": confidence,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in emotion batch {i//batch_size + 1}: {e}\")\n",
    "                # Add default predictions for failed batch\n",
    "                for _ in range(len(batch)):\n",
    "                    results.append(\n",
    "                        {\"label\": \"Trust\", \"score\": 0.0, \"confidence\": \"error\"}\n",
    "                    )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def analyze_results(self, results):\n",
    "        \"\"\"Analyze and display emotion analysis results\"\"\"\n",
    "        total = len(results)\n",
    "\n",
    "        print(f\"\\nðŸ“Š EMOTION ANALYSIS SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"ðŸ“ Total texts: {total}\")\n",
    "\n",
    "        # Emotion distribution\n",
    "        emotion_counts = {}\n",
    "        for emotion in self.emotion_labels:\n",
    "            emotion_counts[emotion] = 0\n",
    "\n",
    "        for result in results:\n",
    "            label = result[\"label\"]\n",
    "            emotion_counts[label] = emotion_counts.get(label, 0) + 1\n",
    "\n",
    "        print(f\"\\nðŸŽ­ Emotion Distribution:\")\n",
    "        # Sort by count, descending\n",
    "        sorted_emotions = sorted(\n",
    "            emotion_counts.items(), key=lambda x: x[1], reverse=True\n",
    "        )\n",
    "        for emotion, count in sorted_emotions:\n",
    "            percentage = (count / total) * 100\n",
    "            emoji = self.emotion_emojis.get(emotion, \"ðŸŽ­\")\n",
    "            print(f\"   {emoji} {emotion}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "        # Confidence distribution\n",
    "        conf_counts = {\"high\": 0, \"medium\": 0, \"low\": 0, \"error\": 0}\n",
    "        for result in results:\n",
    "            conf_counts[result[\"confidence\"]] += 1\n",
    "\n",
    "        print(f\"\\nðŸŽ¯ Confidence Distribution:\")\n",
    "        for conf, count in conf_counts.items():\n",
    "            percentage = (count / total) * 100\n",
    "            print(f\"   {conf.capitalize()}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "        return {\n",
    "            \"total\": total,\n",
    "            \"emotion_distribution\": emotion_counts,\n",
    "            \"confidence_distribution\": conf_counts,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ee5480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Testing EmotionAnalyzer...\n",
      "ðŸ”„ Loading EmoSense Indonesian emotion model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Emotion model loaded successfully!\n",
      "ðŸ”§ Using device: CPU\n",
      "ðŸŽ­ Emotions: Anger, Anticipation, Disgust, Fear, Joy, Sadness, Surprise, Trust\n",
      "\n",
      "ðŸ§ª Testing individual emotion predictions:\n",
      "------------------------------------------------------------\n",
      "Text: 'Saya sangat marah dengan pelayanan ini!'\n",
      "   Expected: Anger\n",
      "   ðŸŽ­ Emotion: ðŸ˜¡ Anger (0.981) - high\n",
      "\n",
      "Text: 'Wah senang sekali dapat hadiah ini!'\n",
      "   Expected: Joy\n",
      "   ðŸŽ­ Emotion: ðŸ˜Š Joy (0.992) - high\n",
      "\n",
      "Text: 'Saya merasa sedih sekali hari ini'\n",
      "   Expected: Sadness\n",
      "   ðŸŽ­ Emotion: ðŸ˜¢ Sadness (0.993) - high\n",
      "\n",
      "Text: 'Ngeri banget nonton film horror tadi'\n",
      "   Expected: Fear\n",
      "   ðŸŽ­ Emotion: ðŸ˜¨ Fear (0.979) - high\n",
      "\n",
      "Text: 'Kaget banget ternyata dia datang!'\n",
      "   Expected: Surprise\n",
      "   ðŸŽ­ Emotion: ðŸ˜² Surprise (0.994) - high\n",
      "\n",
      "Text: 'Jijik banget lihat yang begitu'\n",
      "   Expected: Disgust\n",
      "   ðŸŽ­ Emotion: ðŸ¤¢ Disgust (0.990) - high\n",
      "\n",
      "Text: 'Saya percaya sepenuhnya dengan tim ini'\n",
      "   Expected: Trust\n",
      "   ðŸŽ­ Emotion: ðŸ¤ Trust (0.993) - high\n",
      "\n",
      "Text: 'Tidak sabar menunggu acara besok!'\n",
      "   Expected: Anticipation\n",
      "   ðŸŽ­ Emotion: ðŸ¤” Anticipation (0.989) - high\n",
      "\n",
      "âœ… EmotionAnalyzer test completed!\n"
     ]
    }
   ],
   "source": [
    "# Test EmotionAnalyzer only\n",
    "\n",
    "print(\"ðŸš€ Testing EmotionAnalyzer...\")\n",
    "\n",
    "# Initialize\n",
    "try:\n",
    "    emotion_analyzer = EmotionAnalyzer()\n",
    "\n",
    "    # Test with emotion-specific examples\n",
    "    emotion_test_texts = [\n",
    "        (\"Saya sangat marah dengan pelayanan ini!\", \"Expected: Anger\"),\n",
    "        (\"Wah senang sekali dapat hadiah ini!\", \"Expected: Joy\"),\n",
    "        (\"Saya merasa sedih sekali hari ini\", \"Expected: Sadness\"),\n",
    "        (\"Ngeri banget nonton film horror tadi\", \"Expected: Fear\"),\n",
    "        (\"Kaget banget ternyata dia datang!\", \"Expected: Surprise\"),\n",
    "        (\"Jijik banget lihat yang begitu\", \"Expected: Disgust\"),\n",
    "        (\"Saya percaya sepenuhnya dengan tim ini\", \"Expected: Trust\"),\n",
    "        (\"Tidak sabar menunggu acara besok!\", \"Expected: Anticipation\"),\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nðŸ§ª Testing individual emotion predictions:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for text, expected in emotion_test_texts:\n",
    "        result = emotion_analyzer.predict_single(text)\n",
    "        emotion_emoji = emotion_analyzer.emotion_emojis.get(result[\"label\"], \"ðŸŽ­\")\n",
    "        print(f\"Text: '{text}'\")\n",
    "        print(f\"   {expected}\")\n",
    "        print(\n",
    "            f\"   ðŸŽ­ Emotion: {emotion_emoji} {result['label']} ({result['score']:.3f}) - {result['confidence']}\"\n",
    "        )\n",
    "        print()\n",
    "\n",
    "    print(\"âœ… EmotionAnalyzer test completed!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error in EmotionAnalyzer: {e}\")\n",
    "    import traceback\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a0f9e",
   "metadata": {},
   "source": [
    "# Hate speech Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ce28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateSpeechAnalyzer:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"PaceKW/distilbert-base-multilingual-cased-multilabel-indonesian-hate-speech\",\n",
    "    ):\n",
    "        \"\"\"Initialize hate speech analyzer\"\"\"\n",
    "        print(\"ðŸ”„ Loading Indonesian Hate Speech model...\")\n",
    "\n",
    "        # Using pipeline (simplest approach)\n",
    "        self.pipe = pipeline(\n",
    "            \"text-classification\",\n",
    "            model=model_name,\n",
    "            device=0 if torch.cuda.is_available() else -1,\n",
    "            return_all_scores=True,  # Important for multilabel\n",
    "        )\n",
    "\n",
    "        # Load tokenizer and model separately for more control if needed\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "        # Based on our inspection - we know exactly what labels exist\n",
    "        self.hate_categories = [\n",
    "            \"HS\",\n",
    "            \"Abusive\",\n",
    "            \"HS_Individual\",\n",
    "            \"HS_Group\",\n",
    "            \"HS_Religion\",\n",
    "            \"HS_Race\",\n",
    "            \"HS_Physical\",\n",
    "            \"HS_Gender\",\n",
    "            \"HS_Other\",\n",
    "            \"HS_Weak\",\n",
    "            \"HS_Moderate\",\n",
    "            \"HS_Strong\",\n",
    "        ]\n",
    "\n",
    "        print(\"âœ… Hate speech model loaded successfully!\")\n",
    "        print(f\"ðŸ”§ Using device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "        print(f\"ðŸ·ï¸ Categories: {', '.join(self.hate_categories)}\")\n",
    "\n",
    "    def predict_single(self, text, threshold=0.5):\n",
    "        \"\"\"Predict hate speech for a single text\"\"\"\n",
    "        if pd.isna(text) or text is None or text == \"\" or text == \"No Comment\":\n",
    "            return {\n",
    "                \"is_hate_speech\": False,\n",
    "                \"categories\": [],\n",
    "                \"scores\": {},\n",
    "                \"max_score\": 0.0,\n",
    "                \"confidence\": \"low\",\n",
    "            }\n",
    "\n",
    "        try:\n",
    "            # Get predictions for all labels\n",
    "            results = self.pipe(str(text))\n",
    "\n",
    "            # Debug: Print hasil untuk lihat struktur\n",
    "            print(f\"Debug - Raw result type: {type(results)}\")\n",
    "            print(f\"Debug - Raw result: {results}\")\n",
    "\n",
    "            # Handle different output formats\n",
    "            if isinstance(results, list):\n",
    "                # Jika hasil adalah list of lists (nested)\n",
    "                if len(results) > 0 and isinstance(results[0], list):\n",
    "                    predictions = results[0]  # Ambil list pertama\n",
    "                else:\n",
    "                    predictions = results  # Sudah format yang benar\n",
    "            else:\n",
    "                predictions = [results]  # Bungkus dalam list jika bukan list\n",
    "\n",
    "            # Process multilabel results\n",
    "            active_categories = []\n",
    "            all_scores = {}\n",
    "            max_score = 0.0\n",
    "\n",
    "            for prediction in predictions:\n",
    "                # Handle different key formats\n",
    "                if isinstance(prediction, dict):\n",
    "                    if \"label\" in prediction and \"score\" in prediction:\n",
    "                        label = prediction[\"label\"]\n",
    "                        score = prediction[\"score\"]\n",
    "                    elif \"LABEL\" in prediction and \"SCORE\" in prediction:\n",
    "                        label = prediction[\"LABEL\"]\n",
    "                        score = prediction[\"SCORE\"]\n",
    "                    else:\n",
    "                        print(f\"Debug - Unknown prediction format: {prediction}\")\n",
    "                        continue\n",
    "                else:\n",
    "                    print(f\"Debug - Unexpected prediction type: {type(prediction)}\")\n",
    "                    continue\n",
    "\n",
    "                all_scores[label] = score\n",
    "                max_score = max(max_score, score)\n",
    "\n",
    "                # Add to active categories if above threshold\n",
    "                if score >= threshold:\n",
    "                    active_categories.append(label)\n",
    "\n",
    "            # Determine if hate speech detected\n",
    "            is_hate_speech = len(active_categories) > 0\n",
    "\n",
    "            # Confidence based on max score\n",
    "            if max_score >= 0.8:\n",
    "                confidence = \"high\"\n",
    "            elif max_score >= 0.6:\n",
    "                confidence = \"medium\"\n",
    "            else:\n",
    "                confidence = \"low\"\n",
    "\n",
    "            return {\n",
    "                \"is_hate_speech\": is_hate_speech,\n",
    "                \"categories\": active_categories,\n",
    "                \"scores\": all_scores,\n",
    "                \"max_score\": max_score,\n",
    "                \"confidence\": confidence,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting hate speech: {e}\")\n",
    "            import traceback\n",
    "\n",
    "            traceback.print_exc()\n",
    "            return {\n",
    "                \"is_hate_speech\": False,\n",
    "                \"categories\": [],\n",
    "                \"scores\": {},\n",
    "                \"max_score\": 0.0,\n",
    "                \"confidence\": \"error\",\n",
    "            }\n",
    "\n",
    "    # ... rest of the methods remain the same ...\n",
    "    def predict_batch(self, texts, batch_size=16, threshold=0.5):\n",
    "        \"\"\"Predict hate speech for multiple texts efficiently\"\"\"\n",
    "        results = []\n",
    "\n",
    "        # Convert to list if pandas Series\n",
    "        if hasattr(texts, \"tolist\"):\n",
    "            texts = texts.tolist()\n",
    "\n",
    "        print(f\"ðŸ”„ Processing {len(texts)} texts for hate speech analysis...\")\n",
    "        print(f\"ðŸ“Š Threshold: {threshold} | Batch size: {batch_size}\")\n",
    "\n",
    "        # Process in batches\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Analyzing hate speech\"):\n",
    "            batch = texts[i : i + batch_size]\n",
    "\n",
    "            # Process each text in batch\n",
    "            for text in batch:\n",
    "                result = self.predict_single(text, threshold)\n",
    "                results.append(result)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ffde6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Testing HateSpeechAnalyzer...\n",
      "ðŸ”„ Loading Indonesian Hate Speech model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/Users/rhd/Documents/Raihan/Learning/Data/machine_learning/NLP/.venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hate speech model loaded successfully!\n",
      "ðŸ”§ Using device: CPU\n",
      "ðŸ·ï¸ Categories: HS, Abusive, HS_Individual, HS_Group, HS_Religion, HS_Race, HS_Physical, HS_Gender, HS_Other, HS_Weak, HS_Moderate, HS_Strong\n",
      "\n",
      "ðŸ§ª Testing individual hate speech predictions:\n",
      "------------------------------------------------------------\n",
      "âŒ Error in HateSpeechAnalyzer: name 'pd' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/2b/7ktqrd293f19ydr7g3yl7swr0000gn/T/ipykernel_88538/1200217081.py\", line 27, in <module>\n",
      "    result = hate_analyzer.predict_single(text, threshold=0.5)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/2b/7ktqrd293f19ydr7g3yl7swr0000gn/T/ipykernel_88538/2860086159.py\", line 44, in predict_single\n",
      "    if pd.isna(text) or text is None or text == \"\" or text == \"No Comment\":\n",
      "       ^^\n",
      "NameError: name 'pd' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Test HateSpeechAnalyzer only - FIXED VERSION\n",
    "\n",
    "print(\"ðŸš€ Testing HateSpeechAnalyzer...\")\n",
    "\n",
    "# Initialize\n",
    "try:\n",
    "    # Buat versi yang lebih simple untuk testing\n",
    "    hate_analyzer = HateSpeechAnalyzer()\n",
    "\n",
    "    # Test with hate speech examples\n",
    "    hate_test_texts = [\n",
    "        (\"Selamat pagi semua!\", \"Expected: Clean\"),\n",
    "        (\"Terima kasih atas bantuannya\", \"Expected: Clean\"),\n",
    "        (\"Dasar bodoh tidak tahu apa-apa\", \"Expected: Abusive/HS_Individual\"),\n",
    "        (\"Agama kalian sesat semua\", \"Expected: HS_Religion/HS_Group\"),\n",
    "        (\"Perempuan memang inferior\", \"Expected: HS_Gender\"),\n",
    "        (\"Orang ras itu memang jelek\", \"Expected: HS_Race\"),\n",
    "        (\"Bunuh saja dia\", \"Expected: HS_Strong\"),\n",
    "        (\"Agak aneh sih orangnya\", \"Expected: HS_Weak\"),\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nðŸ§ª Testing individual hate speech predictions:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for text, expected in hate_test_texts:\n",
    "        # Hapus debug print untuk testing yang clean\n",
    "        result = hate_analyzer.predict_single(text, threshold=0.5)\n",
    "\n",
    "        print(f\"Text: '{text}'\")\n",
    "        print(f\"   {expected}\")\n",
    "        hate_status = \"ðŸš¨ YES\" if result[\"is_hate_speech\"] else \"âœ… NO\"\n",
    "        print(\n",
    "            f\"   ðŸš¨ Hate Speech: {hate_status} ({result['max_score']:.3f}) - {result['confidence']}\"\n",
    "        )\n",
    "        if result[\"categories\"]:\n",
    "            print(f\"   ðŸ·ï¸ Categories: {', '.join(result['categories'])}\")\n",
    "        print()\n",
    "\n",
    "    print(\"âœ… HateSpeechAnalyzer test completed!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error in HateSpeechAnalyzer: {e}\")\n",
    "    import traceback\n",
    "\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bb5480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading Indonesian Hate Speech model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hate speech model loaded successfully!\n",
      "ðŸ”§ Using device: CPU\n",
      "ðŸ·ï¸ Categories: HS, Abusive, HS_Individual, HS_Group, HS_Religion, HS_Race, HS_Physical, HS_Gender, HS_Other, HS_Weak, HS_Moderate, HS_Strong\n",
      "Debug - Raw result type: <class 'list'>\n",
      "Debug - Raw result: [[{'label': 'HS', 'score': 0.9977204203605652}, {'label': 'Abusive', 'score': 0.9990230798721313}, {'label': 'HS_Individual', 'score': 0.998616099357605}, {'label': 'HS_Group', 'score': 0.0007585312123410404}, {'label': 'HS_Religion', 'score': 0.00077065295772627}, {'label': 'HS_Race', 'score': 0.0006125601939857006}, {'label': 'HS_Physical', 'score': 0.0011905721621587873}, {'label': 'HS_Gender', 'score': 0.001185533357784152}, {'label': 'HS_Other', 'score': 0.9972537159919739}, {'label': 'HS_Weak', 'score': 0.9980564117431641}, {'label': 'HS_Moderate', 'score': 0.0010938361519947648}, {'label': 'HS_Strong', 'score': 0.0006570350378751755}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'is_hate_speech': True,\n",
       " 'categories': ['HS', 'Abusive', 'HS_Individual', 'HS_Other', 'HS_Weak'],\n",
       " 'scores': {'HS': 0.9977204203605652,\n",
       "  'Abusive': 0.9990230798721313,\n",
       "  'HS_Individual': 0.998616099357605,\n",
       "  'HS_Group': 0.0007585312123410404,\n",
       "  'HS_Religion': 0.00077065295772627,\n",
       "  'HS_Race': 0.0006125601939857006,\n",
       "  'HS_Physical': 0.0011905721621587873,\n",
       "  'HS_Gender': 0.001185533357784152,\n",
       "  'HS_Other': 0.9972537159919739,\n",
       "  'HS_Weak': 0.9980564117431641,\n",
       "  'HS_Moderate': 0.0010938361519947648,\n",
       "  'HS_Strong': 0.0006570350378751755},\n",
       " 'max_score': 0.9990230798721313,\n",
       " 'confidence': 'high'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_analyzer = HateSpeechAnalyzer()\n",
    "\n",
    "hate_analyzer.predict_single(\"Dasar lu bego banget sih.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58269e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUGGING HATE SPEECH MODEL ===\n",
      "\n",
      "1. Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully!\n",
      "\n",
      "2. Testing with: 'Laki-laki di sini mah cemen semua, bener2 gak layak.'\n",
      "\n",
      "--- Method 1: Default prediction ---\n",
      "Type: <class 'list'>\n",
      "Content: [{'label': 'Abusive', 'score': 0.01132898684591055}]\n",
      "JSON: [\n",
      "  {\n",
      "    \"label\": \"Abusive\",\n",
      "    \"score\": 0.01132898684591055\n",
      "  }\n",
      "]\n",
      "\n",
      "--- Method 2: With return_all_scores=True ---\n",
      "Type: <class 'list'>\n",
      "Length: 1\n",
      "Content: [[{'label': 'HS', 'score': 0.00534218642860651}, {'label': 'Abusive', 'score': 0.01132898684591055}, {'label': 'HS_Individual', 'score': 0.002088962122797966}, {'label': 'HS_Group', 'score': 0.003960433881729841}, {'label': 'HS_Religion', 'score': 0.0015794789651408792}, {'label': 'HS_Race', 'score': 0.0012448272900655866}, {'label': 'HS_Physical', 'score': 0.00023130213958211243}, {'label': 'HS_Gender', 'score': 0.0002631369570735842}, {'label': 'HS_Other', 'score': 0.003423444228246808}, {'label': 'HS_Weak', 'score': 0.0018494758987799287}, {'label': 'HS_Moderate', 'score': 0.0031918382737785578}, {'label': 'HS_Strong', 'score': 0.000636451703030616}]]\n",
      "JSON: [\n",
      "  [\n",
      "    {\n",
      "      \"label\": \"HS\",\n",
      "      \"score\": 0.00534218642860651\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"Abusive\",\n",
      "      \"score\": 0.01132898684591055\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"HS_Individual\",\n",
      "      \"score\": 0.002088962122797966\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"HS_Group\",\n",
      "      \"score\": 0.003960433881729841\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"HS_Religion\",\n",
      "      \"score\": 0.0015794789651408792\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"HS_Race\",\n",
      "      \"score\": 0.0012448272900655866\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"HS_Physical\",\n",
      "      \"score\": 0.00023130213958211243\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"HS_Gender\",\n",
      "      \"score\": 0.0002631369570735842\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"HS_Other\",\n",
      "      \"score\": 0.003423444228246808\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"HS_Weak\",\n",
      "      \"score\": 0.0018494758987799287\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"HS_Moderate\",\n",
      "      \"score\": 0.0031918382737785578\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"HS_Strong\",\n",
      "      \"score\": 0.000636451703030616\n",
      "    }\n",
      "  ]\n",
      "]\n",
      "\n",
      "--- Method 4: Model info ---\n",
      "Model name: PaceKW/distilbert-base-multilingual-cased-multilabel-indonesian-hate-speech\n",
      "Task: text-classification\n",
      "Labels: {0: 'HS', 1: 'Abusive', 2: 'HS_Individual', 3: 'HS_Group', 4: 'HS_Religion', 5: 'HS_Race', 6: 'HS_Physical', 7: 'HS_Gender', 8: 'HS_Other', 9: 'HS_Weak', 10: 'HS_Moderate', 11: 'HS_Strong'}\n",
      "Problem type: multi_label_classification\n",
      "\n",
      "=== DEBUG COMPLETE ===\n",
      "Run this first, then tell me what you see!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rhd/Documents/Raihan/Learning/Data/machine_learning/NLP/.venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Simple debugging version\n",
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "print(\"=== DEBUGGING HATE SPEECH MODEL ===\\n\")\n",
    "\n",
    "# Load the model\n",
    "print(\"1. Loading model...\")\n",
    "try:\n",
    "    pipe = pipeline(\n",
    "        \"text-classification\",\n",
    "        model=\"PaceKW/distilbert-base-multilingual-cased-multilabel-indonesian-hate-speech\",\n",
    "    )\n",
    "    print(\"âœ… Model loaded successfully!\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Test text\n",
    "test_text = \"Laki-laki di sini mah cemen semua, bener2 gak layak.\"\n",
    "print(f\"2. Testing with: '{test_text}'\\n\")\n",
    "\n",
    "# Method 1: Default prediction (no return_all_scores)\n",
    "print(\"--- Method 1: Default prediction ---\")\n",
    "try:\n",
    "    result1 = pipe(test_text)\n",
    "    print(f\"Type: {type(result1)}\")\n",
    "    print(f\"Content: {result1}\")\n",
    "    print(f\"JSON: {json.dumps(result1, indent=2, ensure_ascii=False)}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\\n\")\n",
    "\n",
    "# Method 2: With return_all_scores=True\n",
    "print(\"--- Method 2: With return_all_scores=True ---\")\n",
    "try:\n",
    "    result2 = pipe(test_text, return_all_scores=True)\n",
    "    print(f\"Type: {type(result2)}\")\n",
    "    print(f\"Length: {len(result2) if hasattr(result2, '__len__') else 'N/A'}\")\n",
    "    print(f\"Content: {result2}\")\n",
    "    print(f\"JSON: {json.dumps(result2, indent=2, ensure_ascii=False)}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\\n\")\n",
    "\n",
    "# Method 3: Multiple texts\n",
    "# print(\"--- Method 3: Multiple texts ---\")\n",
    "# texts = [\"Kamu jelek\", \"Selamat pagi\"]\n",
    "# try:\n",
    "#     result3 = pipe(texts)\n",
    "#     print(f\"Type: {type(result3)}\")\n",
    "#     print(f\"Length: {len(result3) if hasattr(result3, '__len__') else 'N/A'}\")\n",
    "#     print(f\"Content: {result3}\")\n",
    "#     print(f\"JSON: {json.dumps(result3, indent=2, ensure_ascii=False)}\\n\")\n",
    "# except Exception as e:\n",
    "#     print(f\"âŒ Error: {e}\\n\")\n",
    "\n",
    "# Method 4: Check model config\n",
    "print(\"--- Method 4: Model info ---\")\n",
    "try:\n",
    "    print(f\"Model name: {pipe.model.name_or_path}\")\n",
    "    print(f\"Task: {pipe.task}\")\n",
    "    if hasattr(pipe.model.config, \"id2label\"):\n",
    "        print(f\"Labels: {pipe.model.config.id2label}\")\n",
    "    if hasattr(pipe.model.config, \"problem_type\"):\n",
    "        print(f\"Problem type: {pipe.model.config.problem_type}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error getting model info: {e}\")\n",
    "\n",
    "print(\"\\n=== DEBUG COMPLETE ===\")\n",
    "print(\"Run this first, then tell me what you see!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0f69aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mengunduh model (jika diperlukan)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cahya/bert-base-indonesian-1.5G were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model siap digunakan.\n",
      "\n",
      "--- Tes untuk: 'Ibu kota negara Indonesia adalah [MASK].' ---\n",
      "Kata: jakarta         | Skor Keyakinan: 0.5408\n",
      "Kata: yogyakarta      | Skor Keyakinan: 0.0404\n",
      "Kata: pontianak       | Skor Keyakinan: 0.0294\n",
      "Kata: makassar        | Skor Keyakinan: 0.0170\n",
      "Kata: merauke         | Skor Keyakinan: 0.0158\n",
      "\n",
      "--- Tes untuk: 'Orang yang bekerja di rumah sakit biasanya adalah seorang [MASK].' ---\n",
      "Kalimat Lengkap: orang yang bekerja di rumah sakit biasanya adalah seorang dokter.\n",
      "Kalimat Lengkap: orang yang bekerja di rumah sakit biasanya adalah seorang perawat.\n",
      "Kalimat Lengkap: orang yang bekerja di rumah sakit biasanya adalah seorang bidan.\n",
      "\n",
      "--- Tes untuk: 'Setelah lelah bekerja seharian, enaknya minum [MASK] dingin.' ---\n",
      "Kalimat Lengkap: setelah lelah bekerja seharian, enaknya minum air dingin.\n",
      "Kalimat Lengkap: setelah lelah bekerja seharian, enaknya minum minuman dingin.\n",
      "Kalimat Lengkap: setelah lelah bekerja seharian, enaknya minum teh dingin.\n",
      "\n",
      "--- Tes untuk: 'Dia membeli mobil baru berwarna [MASK].' ---\n",
      "Kalimat Lengkap: dia membeli mobil baru berwarna putih.\n",
      "Kalimat Lengkap: dia membeli mobil baru berwarna hitam.\n",
      "Kalimat Lengkap: dia membeli mobil baru berwarna merah.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 1. Inisialisasi pipeline \"fill-mask\"\n",
    "# Ini akan mengunduh model jika belum ada di cache\n",
    "print(\"Mengunduh model (jika diperlukan)...\")\n",
    "tebak_kata = pipeline(\"fill-mask\", model=\"cahya/bert-base-indonesian-1.5G\")\n",
    "print(\"Model siap digunakan.\")\n",
    "\n",
    "# 2. Siapkan beberapa kalimat tes\n",
    "kalimat1 = \"Ibu kota negara Indonesia adalah [MASK].\"\n",
    "kalimat2 = \"Orang yang bekerja di rumah sakit biasanya adalah seorang [MASK].\"\n",
    "kalimat3 = \"Setelah lelah bekerja seharian, enaknya minum [MASK] dingin.\"\n",
    "kalimat4 = \"Dia membeli mobil baru berwarna [MASK].\"\n",
    "\n",
    "# 3. Lakukan prediksi dan lihat hasilnya\n",
    "print(f\"\\n--- Tes untuk: '{kalimat1}' ---\")\n",
    "hasil1 = tebak_kata(kalimat1)\n",
    "for prediksi in hasil1:\n",
    "    print(\n",
    "        f\"Kata: {prediksi['token_str']:<15} | Skor Keyakinan: {prediksi['score']:.4f}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\n--- Tes untuk: '{kalimat2}' ---\")\n",
    "hasil2 = tebak_kata(kalimat2, top_k=3)  # Minta 3 tebakan teratas\n",
    "for prediksi in hasil2:\n",
    "    print(f\"Kalimat Lengkap: {prediksi['sequence']}\")\n",
    "\n",
    "print(f\"\\n--- Tes untuk: '{kalimat3}' ---\")\n",
    "hasil3 = tebak_kata(kalimat3, top_k=3)\n",
    "for prediksi in hasil3:\n",
    "    print(f\"Kalimat Lengkap: {prediksi['sequence']}\")\n",
    "\n",
    "print(f\"\\n--- Tes untuk: '{kalimat4}' ---\")\n",
    "hasil4 = tebak_kata(kalimat4, top_k=3)\n",
    "for prediksi in hasil4:\n",
    "    print(f\"Kalimat Lengkap: {prediksi['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04c4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
